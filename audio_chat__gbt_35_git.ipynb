{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Voice-Enabled Therapist Chatbot\n",
        "\n",
        "This program uses OpenAI's \"gpt-3.5-turbo\" natural language processing model (which powers ChatGPT) as well as Google's Text-to-Speech (gTTS) library to create a simple therapist chatbot that interacts with the user via voice input and output.  The full conversation history is also displayed as text.\n",
        "\n",
        "The program uses the gradio library to create a user interface that allows the user to record their voice input using their microphone. After the user speaks, the chatbot responds with a text message that is converted into speech and played back to the user.\n",
        "\n",
        "Much of the code taken/adapted from: \n",
        "https://github.com/hackingthemarkets/chatgpt-api-whisper-api-voice-assistant/blob/main/therapist.py\n",
        "\n",
        "Video:\n",
        "https://www.youtube.com/watch?v=Si0vFx_dJ5Y"
      ],
      "metadata": {
        "id": "wezAY-LGu_Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai \n",
        "! pip install gradio \n",
        "! pip install gTTS pyttsx3 playsound"
      ],
      "metadata": {
        "id": "TCZ8FyZf2bCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports \n",
        "import openai\n",
        "import gradio as gr\n",
        "from gtts import gTTS #Import Google Text to Speech\n",
        "from playsound import playsound\n",
        "from IPython.display import Audio #Import Audio method from IPython's Display Classimport subprocess\n",
        "import subprocess\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# OpenAI key required\n",
        "openai.api_key = 'YOUR KEY HERE\" \n",
        "\n",
        "# Create list of messages, starting with initial message to the system\n",
        "messages=[]\n",
        "messages.append({\"role\": \"system\", \"content\": 'You are a therapist. Respond to all input in 25 words or less.'})\n",
        "\n",
        "def transcribe(audio):\n",
        "  \"\"\"\n",
        "  Transcribes the user's audio input using the OpenAI API,\n",
        "  generates a response from the chatbot using GPT-3, converts the response into \n",
        "  speech using the gTTS library, updates the conversation history, and returns \n",
        "  the updated conversation history as a string.\n",
        "\n",
        "  Parameters:\n",
        "  audio (str): The filepath of the audio file containing the user's input.\n",
        "\n",
        "  Returns:\n",
        "  str: A string containing the updated conversation history, with each message formatted as \"role: content\" and separated by two newlines. \n",
        "  \"\"\"\n",
        "  # Declare messages a global variable (not local to the function)\n",
        "  global messages  \n",
        "\n",
        "  # Get user's audio, transcribe it and append it to messages \n",
        "  subprocess.run([\"ffmpeg\", \"-i\", audio, \"3.wav\"], capture_output=True)\n",
        "  audio_file = open(\"3.wav\", \"rb\")\n",
        "  transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "  # print(transcript) # For validation only \n",
        "  messages.append({\"role\": \"user\", \"content\": transcript[\"text\"]})\n",
        "  audio_file.close() # Close the file\n",
        "  !rm 3.wav # deletes file (Google colab environment)   \n",
        "\n",
        "  # Get the therapist's response, append to messages \n",
        "  response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
        "  system_message = response[\"choices\"][0][\"message\"]\n",
        "  messages.append(system_message)\n",
        "\n",
        "  # Create audio from therapist's text response   \n",
        "  msg=system_message[\"content\"]  \n",
        "  # print(msg) # For validation \n",
        "  talk_file=make_into_speech(msg)\n",
        "  display(Audio(talk_file, autoplay=True)) \n",
        "\n",
        "  # Update the rolling chat transcript \n",
        "  chat_transcript = \"\"\n",
        "  for message in messages:\n",
        "      if message['role'] != 'system':\n",
        "          chat_transcript += message['role'] + \": \" + message['content'] + \"\\n\\n\"\n",
        "\n",
        "  return chat_transcript\n",
        "\n",
        "def make_into_speech(words):\n",
        "  \"\"\"\n",
        "  Takes a string as input, converts it to speech using the gTTS library, \n",
        "  saves the speech as a WAV file, and returns the filepath of the saved WAV file.    \n",
        "  Parameters:\n",
        "  - `words` (str): The input string to convert to speech.    \n",
        "  Returns:\n",
        "  - `sound_file` (str): The filepath of the saved WAV file.    \n",
        "  Example:\n",
        "  >>> make_into_speech('Hello, how are you today?')\n",
        "  '2.wav'    \n",
        "  The function converts the input string to speech and returns the filepath of the saved WAV file.\n",
        "  \"\"\"\n",
        "  tts = gTTS(words) #Provide the string to convert to speech\n",
        "  tts.save('2.wav') #Save the string converted to speech as a .wav file\n",
        "  sound_file = '2.wav'\n",
        "  return sound_file\n",
        "\n",
        "# Launch the interface.  Using debug=True in the gradio launch function enables \n",
        "# the automatic display/activation of the audio player in the console; this autoplay \n",
        "# capability is not yet available in gradio without a workaround. \n",
        "ui = gr.Interface(fn=transcribe, inputs=gr.Audio(source=\"microphone\", type=\"filepath\",\n",
        "                  label=\"Record Here -- Hit Clear to Start New Response\"), \n",
        "                  outputs=[gr.Text(label=\"Chat Transcript\")])\n",
        "ui.launch(debug=True)  "
      ],
      "metadata": {
        "id": "1Q3bUzlW91o-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}